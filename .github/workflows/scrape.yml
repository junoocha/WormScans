name: Run Scraper

on:
  workflow_dispatch:
    inputs:
      url:
        description: "URL to scrape"
        required: true
      lazy:
        description: "Use lazy loading (true/false)"
        required: false
        default: "true"

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Python dependencies
        run: pip install -r scraper/requirements.txt

      - name: Cache Playwright browsers
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: ${{ runner.os }}-playwright
          restore-keys: |
            ${{ runner.os }}-playwright

      - name: Install Playwright browsers (skip if cached)
        run: |
          if [ ! -d ~/.cache/ms-playwright ]; then
            playwright install --with-deps
          else
            echo "Playwright cache found, skipping download."
          fi

      - name: Run scraper and save output
        run: |
          mkdir -p output
          # Run scraper with PYTHONPATH so modules are found
          PYTHONPATH=. python scraper/playwright_scraper.py > output/scraper.log
          # Extract all grabbed images into a text file
          grep "Grabbed .* picture[s]*: " output/scraper.log | sed -E 's/.*: (.+)$/\1/' > output/images.txt
        env:
          TARGET_URL: ${{ github.event.inputs.url }}
          USE_LAZY: ${{ github.event.inputs.lazy }}

      - name: Upload scraped artifact
        uses: actions/upload-artifact@v4
        with:
          name: scraped-output
          path: output/
